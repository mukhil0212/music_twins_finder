{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive EDA - Music Taste Twins\n",
    "\n",
    "This notebook provides a comprehensive exploratory data analysis of Spotify user music preferences, including:\n",
    "- Data quality assessment\n",
    "- Feature analysis (univariate, bivariate, multivariate)\n",
    "- Dimensionality reduction (PCA, t-SNE, UMAP)\n",
    "- Comprehensive heatmaps\n",
    "- Statistical distribution plots\n",
    "- Clustering preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project modules\n",
    "from src.utils.helpers import create_sample_data, load_json, validate_data_quality\n",
    "from src.feature_engineering import AudioFeatureExtractor, UserProfileBuilder\n",
    "from src.visualization import (\n",
    "    DimensionalityReducer, HeatmapGenerator, \n",
    "    ClusterVisualizer, EDAVisualizer\n",
    ")\n",
    "from src.clustering import KMeansClustering, HierarchicalClustering\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create sample data\n",
    "try:\n",
    "    # Try to load existing data\n",
    "    users_data = load_json('../data/processed/all_users.json')\n",
    "    print(f\"Loaded {len(users_data)} users from existing data\")\n",
    "except:\n",
    "    # Create sample data\n",
    "    print(\"Creating sample data...\")\n",
    "    users_data = create_sample_data(n_users=200, random_state=42)\n",
    "    print(f\"Created {len(users_data)} sample users\")\n",
    "\n",
    "# Build user profiles\n",
    "profile_builder = UserProfileBuilder()\n",
    "user_profiles, feature_names = profile_builder.build_profiles(users_data)\n",
    "\n",
    "print(f\"\\nUser profiles shape: {user_profiles.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "\n",
    "# Display first few rows\n",
    "user_profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Assessment\n",
    "feature_cols = [col for col in user_profiles.columns \n",
    "                if col not in ['user_id', 'display_name', 'cluster_assignment']]\n",
    "\n",
    "quality_report = validate_data_quality(user_profiles, feature_cols[:20])\n",
    "\n",
    "print(\"=== Data Quality Report ===\")\n",
    "print(f\"Total records: {quality_report['total_records']}\")\n",
    "print(f\"\\nMissing features: {len(quality_report['missing_features'])}\")\n",
    "if quality_report['missing_features']:\n",
    "    print(f\"  - {', '.join(quality_report['missing_features'][:5])}...\")\n",
    "\n",
    "print(f\"\\nFeatures with missing values: {len(quality_report['missing_values'])}\")\n",
    "if quality_report['missing_values']:\n",
    "    for feature, info in list(quality_report['missing_values'].items())[:5]:\n",
    "        print(f\"  - {feature}: {info['count']} ({info['percentage']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nWarnings:\")\n",
    "for warning in quality_report['warnings']:\n",
    "    print(f\"  ⚠️  {warning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Analysis - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EDA visualizer\n",
    "eda_viz = EDAVisualizer()\n",
    "\n",
    "# Select key audio features for analysis\n",
    "audio_features = [\n",
    "    'danceability_mean', 'energy_mean', 'valence_mean', 'acousticness_mean',\n",
    "    'instrumentalness_mean', 'speechiness_mean', 'liveness_mean', 'tempo_mean'\n",
    "]\n",
    "\n",
    "# Create feature distributions\n",
    "eda_viz.create_feature_distributions(\n",
    "    user_profiles, \n",
    "    audio_features,\n",
    "    save_path='../data/visualizations/feature_distributions.png'\n",
    ")\n",
    "\n",
    "# Display basic statistics\n",
    "user_profiles[audio_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze skewness and kurtosis\n",
    "skewness_data = user_profiles[feature_cols].skew().sort_values(ascending=False)\n",
    "kurtosis_data = user_profiles[feature_cols].kurtosis().sort_values(ascending=False)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Skewness\n",
    "top_skewed = skewness_data.head(15)\n",
    "colors = ['red' if abs(s) > 1 else 'yellow' if abs(s) > 0.5 else 'green' for s in top_skewed]\n",
    "top_skewed.plot(kind='barh', ax=ax1, color=colors)\n",
    "ax1.set_title('Top 15 Features by Skewness')\n",
    "ax1.set_xlabel('Skewness')\n",
    "ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Kurtosis\n",
    "top_kurtosis = kurtosis_data.head(15)\n",
    "colors = ['red' if k > 3 else 'yellow' if k > 1 else 'green' for k in top_kurtosis]\n",
    "top_kurtosis.plot(kind='barh', ax=ax2, color=colors)\n",
    "ax2.set_title('Top 15 Features by Kurtosis')\n",
    "ax2.set_xlabel('Kurtosis')\n",
    "ax2.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Features with high skewness (|skew| > 1):\")\n",
    "print(skewness_data[abs(skewness_data) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis - Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "eda_viz.create_correlation_analysis(\n",
    "    user_profiles,\n",
    "    audio_features + ['genre_diversity', 'listening_diversity', 'artist_consistency'],\n",
    "    save_path='../data/visualizations/correlation_analysis.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive scatter plot matrix\n",
    "selected_features = ['energy_mean', 'valence_mean', 'danceability_mean', \n",
    "                    'acousticness_mean', 'genre_diversity', 'listening_diversity']\n",
    "\n",
    "# Add temporary cluster labels for visualization\n",
    "kmeans = KMeansClustering(n_clusters=5)\n",
    "X = user_profiles[feature_cols].values\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "user_profiles['cluster'] = cluster_labels\n",
    "\n",
    "# Create scatter matrix\n",
    "fig = eda_viz.create_scatter_plot_matrix(\n",
    "    user_profiles,\n",
    "    selected_features,\n",
    "    cluster_column='cluster',\n",
    "    save_path='../data/visualizations/scatter_matrix.html'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap generator\n",
    "heatmap_gen = HeatmapGenerator()\n",
    "\n",
    "# 1. Feature Correlation Heatmap (with hierarchical clustering)\n",
    "corr_matrix = heatmap_gen.create_feature_correlation_heatmap(\n",
    "    user_profiles[feature_cols[:30]],  # Top 30 features\n",
    "    save_path='../data/visualizations/feature_correlation_clustered.png',\n",
    "    clustered=True,\n",
    "    figsize=(14, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. User Similarity Heatmap\n",
    "from src.similarity import SimilarityMatcher\n",
    "\n",
    "# Create similarity matcher\n",
    "matcher = SimilarityMatcher(metric='cosine')\n",
    "matcher.fit(X, user_profiles['user_id'].tolist(), cluster_labels)\n",
    "\n",
    "# Calculate similarity matrix for subset of users\n",
    "sample_users = user_profiles['user_id'].sample(50).tolist()\n",
    "similarity_matrix = matcher.calculate_similarity_matrix(sample_users)\n",
    "\n",
    "# Create heatmap\n",
    "heatmap_gen.create_user_similarity_heatmap(\n",
    "    similarity_matrix,\n",
    "    sample_users,\n",
    "    cluster_labels[:50],\n",
    "    save_path='../data/visualizations/user_similarity_heatmap.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Cluster Feature Heatmap\n",
    "cluster_stats = kmeans.get_cluster_statistics(X, feature_cols)\n",
    "\n",
    "heatmap_gen.create_cluster_feature_heatmap(\n",
    "    cluster_stats,\n",
    "    audio_features + ['genre_diversity', 'artist_consistency'],\n",
    "    save_path='../data/visualizations/cluster_features_heatmap.png',\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Genre Distribution Heatmap\n",
    "# Extract genre data\n",
    "genre_data = {}\n",
    "for user in users_data:\n",
    "    genre_data[user['user_id']] = user.get('genre_distribution', {})\n",
    "\n",
    "# Create cluster labels mapping\n",
    "cluster_labels_dict = dict(zip(user_profiles['user_id'], user_profiles['cluster']))\n",
    "\n",
    "heatmap_gen.create_genre_distribution_heatmap(\n",
    "    genre_data,\n",
    "    cluster_labels_dict,\n",
    "    save_path='../data/visualizations/genre_distribution_heatmap.png',\n",
    "    top_n_genres=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Temporal Listening Patterns Heatmap\n",
    "# Extract temporal data\n",
    "temporal_data = {}\n",
    "for user in users_data:\n",
    "    temporal_data[user['user_id']] = user.get('listening_patterns', {})\n",
    "\n",
    "heatmap_gen.create_temporal_heatmap(\n",
    "    temporal_data,\n",
    "    save_path='../data/visualizations/temporal_patterns_heatmap.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction - PCA, t-SNE, UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimensionality reducer\n",
    "dim_reducer = DimensionalityReducer()\n",
    "\n",
    "# Apply PCA\n",
    "pca_results = dim_reducer.apply_pca(X, n_components=min(10, X.shape[1]))\n",
    "\n",
    "# Plot PCA analysis\n",
    "dim_reducer.plot_pca_analysis(\n",
    "    feature_cols,\n",
    "    cluster_labels,\n",
    "    save_path='../data/visualizations/pca_analysis_detailed.png'\n",
    ")\n",
    "\n",
    "# Print explained variance\n",
    "print(\"PCA Explained Variance Ratio:\")\n",
    "for i, var in enumerate(pca_results['explained_variance_ratio'][:5]):\n",
    "    print(f\"  PC{i+1}: {var:.3f} ({pca_results['cumulative_variance_ratio'][i]:.3f} cumulative)\")\n",
    "\n",
    "print(f\"\\nComponents needed for 80% variance: {np.argmax(pca_results['cumulative_variance_ratio'] >= 0.8) + 1}\")\n",
    "print(f\"Components needed for 90% variance: {np.argmax(pca_results['cumulative_variance_ratio'] >= 0.9) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE with different perplexity values\n",
    "print(\"Applying t-SNE (this may take a few minutes)...\")\n",
    "tsne_results = dim_reducer.apply_tsne(X, perplexity_values=[5, 30, 50])\n",
    "\n",
    "# Plot t-SNE comparison\n",
    "dim_reducer.plot_tsne_comparison(\n",
    "    cluster_labels,\n",
    "    user_profiles['user_id'].tolist(),\n",
    "    save_path='../data/visualizations/tsne_perplexity_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP with different parameters\n",
    "print(\"Applying UMAP...\")\n",
    "umap_results = dim_reducer.apply_umap(\n",
    "    X,\n",
    "    n_neighbors_values=[5, 15, 30],\n",
    "    min_dist_values=[0.1, 0.25, 0.5]\n",
    ")\n",
    "\n",
    "# Plot UMAP comparison\n",
    "dim_reducer.plot_umap_comparison(\n",
    "    cluster_labels,\n",
    "    save_path='../data/visualizations/umap_parameter_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods side by side\n",
    "dim_reducer.plot_all_methods_comparison(\n",
    "    cluster_labels,\n",
    "    save_path='../data/visualizations/dimensionality_reduction_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive 3D PCA plot\n",
    "fig_3d = dim_reducer.create_interactive_3d_plot(\n",
    "    method='pca',\n",
    "    cluster_labels=cluster_labels,\n",
    "    user_ids=user_profiles['user_id'].tolist(),\n",
    "    save_path='../data/visualizations/pca_3d_interactive.html'\n",
    ")\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistical summary\n",
    "eda_viz.create_statistical_summary(\n",
    "    user_profiles,\n",
    "    feature_cols[:30],  # Top 30 features\n",
    "    cluster_column='cluster',\n",
    "    save_path='../data/visualizations/statistical_summary_detailed.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection analysis\n",
    "eda_viz.create_outlier_detection_plots(\n",
    "    user_profiles,\n",
    "    audio_features,\n",
    "    save_path='../data/visualizations/outlier_analysis.png'\n",
    ")\n",
    "\n",
    "# Count outliers per feature\n",
    "outlier_summary = {}\n",
    "for feature in audio_features:\n",
    "    Q1 = user_profiles[feature].quantile(0.25)\n",
    "    Q3 = user_profiles[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((user_profiles[feature] < (Q1 - 1.5 * IQR)) | \n",
    "                (user_profiles[feature] > (Q3 + 1.5 * IQR))).sum()\n",
    "    outlier_summary[feature] = outliers\n",
    "\n",
    "print(\"Outlier Summary:\")\n",
    "for feature, count in sorted(outlier_summary.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {feature}: {count} outliers ({count/len(user_profiles)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots by cluster\n",
    "eda_viz.create_box_plots_by_cluster(\n",
    "    user_profiles,\n",
    "    audio_features,\n",
    "    cluster_column='cluster',\n",
    "    save_path='../data/visualizations/box_plots_by_cluster.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots for detailed distributions\n",
    "eda_viz.create_violin_plots(\n",
    "    user_profiles,\n",
    "    audio_features,\n",
    "    cluster_column='cluster',\n",
    "    save_path='../data/visualizations/violin_plots_by_cluster.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clustering Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "from src.feature_engineering import AudioFeatureExtractor\n",
    "\n",
    "extractor = AudioFeatureExtractor()\n",
    "feature_importance = extractor.get_feature_importance(X)\n",
    "\n",
    "# Plot feature importance\n",
    "eda_viz.create_feature_importance_analysis(\n",
    "    feature_importance,\n",
    "    save_path='../data/visualizations/feature_importance_analysis.png'\n",
    ")\n",
    "\n",
    "# Display top features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters\n",
    "print(\"Finding optimal number of clusters...\")\n",
    "elbow_results = kmeans.find_optimal_k(X, k_range=range(2, 16))\n",
    "\n",
    "# Plot elbow curve\n",
    "kmeans.plot_elbow_curve(\n",
    "    elbow_results,\n",
    "    save_path='../data/visualizations/elbow_curve_analysis.png'\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimal K (elbow method): {elbow_results['optimal_k_elbow']}\")\n",
    "print(f\"Optimal K (silhouette): {elbow_results['optimal_k_silhouette']}\")\n",
    "print(f\"Recommended K: {elbow_results['recommended_k']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different clustering algorithms\n",
    "from src.clustering.evaluation_metrics import ClusteringEvaluator\n",
    "\n",
    "# K-means with optimal k\n",
    "kmeans_optimal = KMeansClustering(n_clusters=elbow_results['recommended_k'])\n",
    "kmeans_labels = kmeans_optimal.fit_predict(X)\n",
    "\n",
    "# Hierarchical clustering\n",
    "hierarchical = HierarchicalClustering(n_clusters=elbow_results['recommended_k'])\n",
    "hierarchical_labels = hierarchical.fit_predict(X)\n",
    "\n",
    "# Compare results\n",
    "evaluator = ClusteringEvaluator()\n",
    "comparison_df = evaluator.compare_clusterings(\n",
    "    X,\n",
    "    {\n",
    "        'K-means': kmeans_labels,\n",
    "        'Hierarchical': hierarchical_labels\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Clustering Algorithm Comparison:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time-based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal listening patterns\n",
    "eda_viz.create_time_series_analysis(\n",
    "    temporal_data,\n",
    "    save_path='../data/visualizations/temporal_analysis.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final summary dashboard\n",
    "cluster_viz = ClusterVisualizer()\n",
    "\n",
    "# Update cluster stats with optimal clustering\n",
    "user_profiles['cluster'] = kmeans_labels\n",
    "final_cluster_stats = kmeans_optimal.get_cluster_statistics(X, feature_cols)\n",
    "\n",
    "# Create summary dashboard\n",
    "cluster_viz.create_cluster_summary_dashboard(\n",
    "    final_cluster_stats,\n",
    "    user_profiles,\n",
    "    save_path='../data/visualizations/cluster_summary_dashboard.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights summary\n",
    "print(\"=== KEY INSIGHTS ===\")\n",
    "print(f\"\\n1. DATA SUMMARY:\")\n",
    "print(f\"   - Total users analyzed: {len(user_profiles)}\")\n",
    "print(f\"   - Total features: {len(feature_cols)}\")\n",
    "print(f\"   - Optimal number of clusters: {elbow_results['recommended_k']}\")\n",
    "\n",
    "print(f\"\\n2. CLUSTER CHARACTERISTICS:\")\n",
    "for i in range(elbow_results['recommended_k']):\n",
    "    cluster_size = (user_profiles['cluster'] == i).sum()\n",
    "    print(f\"   - Cluster {i}: {cluster_size} users ({cluster_size/len(user_profiles)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n3. TOP DISTINGUISHING FEATURES:\")\n",
    "top_features = feature_importance.head(10)['feature'].tolist()\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "\n",
    "print(f\"\\n4. DIMENSIONALITY REDUCTION:\")\n",
    "print(f\"   - PCA: {np.argmax(pca_results['cumulative_variance_ratio'] >= 0.8) + 1} components for 80% variance\")\n",
    "print(f\"   - Best t-SNE perplexity: 30\")\n",
    "print(f\"   - Best UMAP parameters: n_neighbors=15, min_dist=0.1\")\n",
    "\n",
    "print(f\"\\n5. DATA QUALITY:\")\n",
    "print(f\"   - Features with outliers: {len([f for f, c in outlier_summary.items() if c > 0])}\")\n",
    "print(f\"   - Most skewed features: {list(skewness_data[abs(skewness_data) > 1].index[:3])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "output_path = '../data/processed/user_profiles_with_clusters.csv'\n",
    "user_profiles.to_csv(output_path, index=False)\n",
    "print(f\"\\nProcessed data saved to: {output_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('../data/processed/feature_importance.csv', index=False)\n",
    "print(\"Feature importance saved to: ../data/processed/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive EDA has revealed:\n",
    "\n",
    "1. **Data Quality**: The dataset is generally clean with minimal missing values\n",
    "2. **Feature Distributions**: Most audio features follow approximately normal distributions\n",
    "3. **Clustering Structure**: Clear clustering patterns exist in the data\n",
    "4. **Dimensionality Reduction**: PCA, t-SNE, and UMAP all reveal meaningful structure\n",
    "5. **Key Features**: Energy, valence, and danceability are among the most important distinguishing features\n",
    "\n",
    "The analysis provides a solid foundation for building the music taste similarity system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}