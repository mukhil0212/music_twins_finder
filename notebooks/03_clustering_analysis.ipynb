{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Clustering Analysis\n",
    "\n",
    "This notebook performs clustering analysis to identify groups of users with similar music tastes using various clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load different feature sets\n",
    "user_features_full = pd.read_csv('../data/processed/user_features_scaled.csv')\n",
    "user_features_pca = pd.read_csv('../data/processed/user_features_pca.csv')\n",
    "user_features_selected = pd.read_csv('../data/processed/user_features_selected.csv')\n",
    "\n",
    "print(\"Available feature sets:\")\n",
    "print(f\"1. Full features: {user_features_full.shape}\")\n",
    "print(f\"2. PCA features: {user_features_pca.shape}\")\n",
    "print(f\"3. Selected features: {user_features_selected.shape}\")\n",
    "\n",
    "# Use selected features for clustering\n",
    "user_features = user_features_selected.copy()\n",
    "feature_cols = [col for col in user_features.columns if col != 'user_id']\n",
    "X = user_features[feature_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method for K-means\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 15)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
    "\n",
    "# Plot elbow curve and silhouette scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow curve\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Method for Optimal k')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Silhouette scores\n",
    "ax2.plot(k_range, silhouette_scores, 'go-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score vs k')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find optimal k based on silhouette score\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal k based on silhouette score: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering with optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=20)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "user_features['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "# Cluster statistics\n",
    "cluster_sizes = pd.Series(kmeans_labels).value_counts().sort_index()\n",
    "print(\"K-Means Cluster Sizes:\")\n",
    "for cluster, size in cluster_sizes.items():\n",
    "    print(f\"  Cluster {cluster}: {size} users ({size/len(user_features)*100:.1f}%)\")\n",
    "\n",
    "# Clustering metrics\n",
    "print(f\"\\nClustering Metrics:\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X, kmeans_labels):.3f}\")\n",
    "print(f\"Davies-Bouldin Score: {davies_bouldin_score(X, kmeans_labels):.3f}\")\n",
    "print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(X, kmeans_labels):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')\n",
    "hierarchical_labels = hierarchical.fit_predict(X)\n",
    "\n",
    "user_features['hierarchical_cluster'] = hierarchical_labels\n",
    "\n",
    "# Compare with K-means\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari_score = adjusted_rand_score(kmeans_labels, hierarchical_labels)\n",
    "print(f\"Adjusted Rand Index between K-means and Hierarchical: {ari_score:.3f}\")\n",
    "\n",
    "# Cluster sizes\n",
    "hier_cluster_sizes = pd.Series(hierarchical_labels).value_counts().sort_index()\n",
    "print(\"\\nHierarchical Cluster Sizes:\")\n",
    "for cluster, size in hier_cluster_sizes.items():\n",
    "    print(f\"  Cluster {cluster}: {size} users ({size/len(user_features)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal DBSCAN parameters\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Calculate k-distance graph\n",
    "k = 5  # minPts\n",
    "nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "distances = np.sort(distances[:, k-1], axis=0)\n",
    "\n",
    "# Plot k-distance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.ylabel(f'{k}-NN Distance')\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.title('k-distance Graph for DBSCAN')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Estimate eps from the elbow\n",
    "eps = np.percentile(distances, 95)  # Use 95th percentile as eps\n",
    "print(f\"Suggested eps: {eps:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=eps, min_samples=k)\n",
    "dbscan_labels = dbscan.fit_predict(X)\n",
    "\n",
    "user_features['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "# DBSCAN statistics\n",
    "n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"DBSCAN Results:\")\n",
    "print(f\"Number of clusters: {n_clusters}\")\n",
    "print(f\"Number of noise points: {n_noise} ({n_noise/len(user_features)*100:.1f}%)\")\n",
    "\n",
    "if n_clusters > 1:\n",
    "    # Calculate metrics only for non-noise points\n",
    "    mask = dbscan_labels != -1\n",
    "    if sum(mask) > 0:\n",
    "        print(f\"\\nDBSCAN Metrics (excluding noise):\")\n",
    "        print(f\"Silhouette Score: {silhouette_score(X[mask], dbscan_labels[mask]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions for visualization\n",
    "print(\"Computing 2D projections for visualization...\")\n",
    "\n",
    "# PCA projection\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "X_pca_2d = pca_2d.fit_transform(X)\n",
    "\n",
    "# t-SNE projection (sample if too many points)\n",
    "if len(X) > 5000:\n",
    "    sample_idx = np.random.choice(len(X), 5000, replace=False)\n",
    "    X_tsne_sample = X[sample_idx]\n",
    "    labels_sample = kmeans_labels[sample_idx]\n",
    "else:\n",
    "    X_tsne_sample = X\n",
    "    labels_sample = kmeans_labels\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne_2d = tsne.fit_transform(X_tsne_sample)\n",
    "\n",
    "# UMAP projection\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap_2d = umap_reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# PCA visualizations\n",
    "scatter1 = axes[0, 0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], \n",
    "                             c=kmeans_labels, cmap='viridis', alpha=0.6)\n",
    "axes[0, 0].set_title('K-Means Clusters (PCA)')\n",
    "axes[0, 0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%} var)')\n",
    "axes[0, 0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%} var)')\n",
    "\n",
    "# t-SNE visualizations\n",
    "scatter2 = axes[0, 1].scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], \n",
    "                             c=labels_sample, cmap='viridis', alpha=0.6)\n",
    "axes[0, 1].set_title('K-Means Clusters (t-SNE)')\n",
    "axes[0, 1].set_xlabel('t-SNE 1')\n",
    "axes[0, 1].set_ylabel('t-SNE 2')\n",
    "\n",
    "# UMAP visualizations\n",
    "scatter3 = axes[0, 2].scatter(X_umap_2d[:, 0], X_umap_2d[:, 1], \n",
    "                             c=kmeans_labels, cmap='viridis', alpha=0.6)\n",
    "axes[0, 2].set_title('K-Means Clusters (UMAP)')\n",
    "axes[0, 2].set_xlabel('UMAP 1')\n",
    "axes[0, 2].set_ylabel('UMAP 2')\n",
    "\n",
    "# Hierarchical clustering\n",
    "scatter4 = axes[1, 0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], \n",
    "                             c=hierarchical_labels, cmap='plasma', alpha=0.6)\n",
    "axes[1, 0].set_title('Hierarchical Clusters (PCA)')\n",
    "axes[1, 0].set_xlabel(f'PC1')\n",
    "axes[1, 0].set_ylabel(f'PC2')\n",
    "\n",
    "# DBSCAN clustering\n",
    "scatter5 = axes[1, 1].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], \n",
    "                             c=dbscan_labels, cmap='coolwarm', alpha=0.6)\n",
    "axes[1, 1].set_title('DBSCAN Clusters (PCA)')\n",
    "axes[1, 1].set_xlabel(f'PC1')\n",
    "axes[1, 1].set_ylabel(f'PC2')\n",
    "\n",
    "# Cluster size comparison\n",
    "cluster_methods = ['K-Means', 'Hierarchical', 'DBSCAN']\n",
    "cluster_counts = [\n",
    "    len(set(kmeans_labels)),\n",
    "    len(set(hierarchical_labels)),\n",
    "    len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "]\n",
    "axes[1, 2].bar(cluster_methods, cluster_counts)\n",
    "axes[1, 2].set_title('Number of Clusters by Method')\n",
    "axes[1, 2].set_ylabel('Number of Clusters')\n",
    "\n",
    "# Add colorbars\n",
    "for ax, scatter in zip([axes[0, 0], axes[0, 1], axes[0, 2], axes[1, 0], axes[1, 1]], \n",
    "                      [scatter1, scatter2, scatter3, scatter4, scatter5]):\n",
    "    plt.colorbar(scatter, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "# Focus on K-means clusters\n",
    "cluster_profiles = user_features.groupby('kmeans_cluster')[feature_cols].mean()\n",
    "\n",
    "# Normalize profiles to show relative differences\n",
    "cluster_profiles_norm = (cluster_profiles - cluster_profiles.mean()) / cluster_profiles.std()\n",
    "\n",
    "# Select top distinguishing features\n",
    "feature_variance = cluster_profiles_norm.var()\n",
    "top_features = feature_variance.nlargest(10).index.tolist()\n",
    "\n",
    "# Create heatmap of cluster profiles\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_profiles_norm[top_features].T, \n",
    "            cmap='RdBu_r', center=0, \n",
    "            cbar_kws={'label': 'Standardized Value'},\n",
    "            xticklabels=[f'Cluster {i}' for i in range(optimal_k)],\n",
    "            yticklabels=top_features)\n",
    "plt.title('Cluster Profiles - Top Distinguishing Features')\n",
    "plt.xlabel('Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed cluster descriptions\n",
    "print(\"=== CLUSTER DESCRIPTIONS ===\")\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = cluster_profiles_norm.loc[cluster]\n",
    "    \n",
    "    print(f\"\\nCluster {cluster} ({cluster_sizes[cluster]} users):\")\n",
    "    \n",
    "    # Top positive features\n",
    "    top_positive = cluster_data.nlargest(3)\n",
    "    print(\"  Highest features:\")\n",
    "    for feat, val in top_positive.items():\n",
    "        print(f\"    - {feat}: {val:.2f} std above average\")\n",
    "    \n",
    "    # Top negative features\n",
    "    top_negative = cluster_data.nsmallest(3)\n",
    "    print(\"  Lowest features:\")\n",
    "    for feat, val in top_negative.items():\n",
    "        print(f\"    - {feat}: {val:.2f} std below average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Distribution by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If genre features are available, analyze genre preferences by cluster\n",
    "genre_cols = [col for col in feature_cols if col.startswith('genre_')]\n",
    "\n",
    "if genre_cols:\n",
    "    # Get average genre preferences by cluster\n",
    "    genre_by_cluster = user_features.groupby('kmeans_cluster')[genre_cols].mean()\n",
    "    \n",
    "    # Plot top genres for each cluster\n",
    "    fig, axes = plt.subplots(2, int(np.ceil(optimal_k/2)), figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for cluster in range(optimal_k):\n",
    "        top_genres = genre_by_cluster.loc[cluster].nlargest(5)\n",
    "        \n",
    "        axes[cluster].bar(range(len(top_genres)), top_genres.values)\n",
    "        axes[cluster].set_xticks(range(len(top_genres)))\n",
    "        axes[cluster].set_xticklabels([g.replace('genre_', '') for g in top_genres.index], \n",
    "                                      rotation=45, ha='right')\n",
    "        axes[cluster].set_title(f'Cluster {cluster} - Top Genres')\n",
    "        axes[cluster].set_ylabel('Average Preference')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(optimal_k, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No genre features available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save user clusters\n",
    "cluster_results = user_features[['user_id', 'kmeans_cluster', 'hierarchical_cluster', 'dbscan_cluster']]\n",
    "cluster_results.to_csv('../data/processed/user_clusters.csv', index=False)\n",
    "\n",
    "# Save cluster profiles\n",
    "cluster_profiles.to_csv('../data/processed/cluster_profiles.csv')\n",
    "\n",
    "# Save clustering models\n",
    "import joblib\n",
    "joblib.dump(kmeans, '../models/kmeans_model.pkl')\n",
    "joblib.dump(hierarchical, '../models/hierarchical_model.pkl')\n",
    "joblib.dump(dbscan, '../models/dbscan_model.pkl')\n",
    "\n",
    "# Save 2D projections for visualization\n",
    "projections = pd.DataFrame({\n",
    "    'user_id': user_features['user_id'],\n",
    "    'pca_1': X_pca_2d[:, 0],\n",
    "    'pca_2': X_pca_2d[:, 1],\n",
    "    'umap_1': X_umap_2d[:, 0],\n",
    "    'umap_2': X_umap_2d[:, 1]\n",
    "})\n",
    "projections.to_csv('../data/processed/cluster_projections.csv', index=False)\n",
    "\n",
    "print(\"Clustering results saved!\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"- user_clusters.csv: User cluster assignments\")\n",
    "print(\"- cluster_profiles.csv: Average feature values by cluster\")\n",
    "print(\"- cluster_projections.csv: 2D projections for visualization\")\n",
    "print(\"\\nSaved models:\")\n",
    "print(\"- kmeans_model.pkl\")\n",
    "print(\"- hierarchical_model.pkl\")\n",
    "print(\"- dbscan_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "print(\"=== CLUSTERING ANALYSIS SUMMARY ===\")\n",
    "print(f\"\\nDataset: {len(user_features)} users, {len(feature_cols)} features\")\n",
    "print(f\"\\nOptimal number of clusters: {optimal_k}\")\n",
    "\n",
    "print(\"\\n=== METHOD COMPARISON ===\")\n",
    "methods_comparison = pd.DataFrame({\n",
    "    'Method': ['K-Means', 'Hierarchical', 'DBSCAN'],\n",
    "    'Clusters': [optimal_k, optimal_k, n_clusters],\n",
    "    'Silhouette': [\n",
    "        silhouette_score(X, kmeans_labels),\n",
    "        silhouette_score(X, hierarchical_labels),\n",
    "        silhouette_score(X[dbscan_labels != -1], dbscan_labels[dbscan_labels != -1]) if n_clusters > 1 else np.nan\n",
    "    ]\n",
    "})\n",
    "print(methods_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== CLUSTER CHARACTERISTICS ===\")\n",
    "print(\"K-Means clusters show distinct patterns in:\")\n",
    "for i, feat in enumerate(feature_variance.nlargest(5).index):\n",
    "    print(f\"  {i+1}. {feat}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(f\"- Use K-Means with {optimal_k} clusters for production\")\n",
    "print(f\"- Clusters are well-separated (silhouette score: {silhouette_score(X, kmeans_labels):.3f})\")\n",
    "print(f\"- Focus on top {len(top_features)} features for interpretation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}