{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Feature Engineering\n",
    "\n",
    "This notebook creates user profiles based on listening history and audio features, preparing data for clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "listening_history = pd.read_csv('../data/raw/listening_history.csv')\n",
    "track_features = pd.read_csv('../data/raw/track_features.csv')\n",
    "\n",
    "# Convert timestamp\n",
    "listening_history['datetime'] = pd.to_datetime(listening_history['timestamp'])\n",
    "\n",
    "print(f\"Listening events: {listening_history.shape[0]:,}\")\n",
    "print(f\"Unique users: {listening_history['user_id'].nunique():,}\")\n",
    "print(f\"Unique tracks: {listening_history['track_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create User-Track Play Count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate play counts per user-track pair\n",
    "user_track_plays = listening_history.groupby(['user_id', 'track_id']).size().reset_index(name='play_count')\n",
    "\n",
    "# Filter users with minimum activity\n",
    "MIN_USER_PLAYS = 20\n",
    "user_total_plays = user_track_plays.groupby('user_id')['play_count'].sum()\n",
    "active_users = user_total_plays[user_total_plays >= MIN_USER_PLAYS].index\n",
    "\n",
    "print(f\"Active users (>={MIN_USER_PLAYS} plays): {len(active_users):,}\")\n",
    "\n",
    "# Filter data to active users\n",
    "user_track_plays = user_track_plays[user_track_plays['user_id'].isin(active_users)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Feature Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define audio features to use\n",
    "audio_features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "                  'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "# Check which features are available\n",
    "available_features = [f for f in audio_features if f in track_features.columns]\n",
    "print(f\"Available audio features: {available_features}\")\n",
    "\n",
    "# Merge play counts with track features\n",
    "user_track_features = user_track_plays.merge(\n",
    "    track_features[['track_id'] + available_features], \n",
    "    on='track_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check feature coverage\n",
    "coverage = user_track_features[available_features].notna().all(axis=1).mean() * 100\n",
    "print(f\"\\nFeature coverage: {coverage:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted average features per user\n",
    "def calculate_weighted_features(df, features, weight_col='play_count'):\n",
    "    \"\"\"\n",
    "    Calculate weighted average of features based on play counts\n",
    "    \"\"\"\n",
    "    user_features = {}\n",
    "    \n",
    "    for user_id in df['user_id'].unique():\n",
    "        user_data = df[df['user_id'] == user_id]\n",
    "        \n",
    "        # Remove tracks with missing features\n",
    "        user_data = user_data.dropna(subset=features)\n",
    "        \n",
    "        if len(user_data) > 0:\n",
    "            weights = user_data[weight_col]\n",
    "            weighted_features = {}\n",
    "            \n",
    "            for feature in features:\n",
    "                weighted_avg = np.average(user_data[feature], weights=weights)\n",
    "                weighted_features[f'avg_{feature}'] = weighted_avg\n",
    "                \n",
    "                # Also calculate std deviation for diversity\n",
    "                if len(user_data) > 1:\n",
    "                    weighted_features[f'std_{feature}'] = np.sqrt(\n",
    "                        np.average((user_data[feature] - weighted_avg)**2, weights=weights)\n",
    "                    )\n",
    "                else:\n",
    "                    weighted_features[f'std_{feature}'] = 0\n",
    "            \n",
    "            user_features[user_id] = weighted_features\n",
    "    \n",
    "    return pd.DataFrame.from_dict(user_features, orient='index')\n",
    "\n",
    "# Calculate user audio profiles\n",
    "user_audio_profiles = calculate_weighted_features(user_track_features, available_features)\n",
    "user_audio_profiles.index.name = 'user_id'\n",
    "user_audio_profiles = user_audio_profiles.reset_index()\n",
    "\n",
    "print(f\"User audio profiles shape: {user_audio_profiles.shape}\")\n",
    "user_audio_profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listening Behavior Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate listening behavior features\n",
    "behavior_features = []\n",
    "\n",
    "for user_id in active_users:\n",
    "    user_history = listening_history[listening_history['user_id'] == user_id]\n",
    "    user_plays = user_track_plays[user_track_plays['user_id'] == user_id]\n",
    "    \n",
    "    features = {\n",
    "        'user_id': user_id,\n",
    "        'total_plays': len(user_history),\n",
    "        'unique_tracks': user_plays['track_id'].nunique(),\n",
    "        'avg_plays_per_track': user_plays['play_count'].mean(),\n",
    "        'play_count_std': user_plays['play_count'].std(),\n",
    "        'track_diversity': user_plays['track_id'].nunique() / len(user_history),\n",
    "    }\n",
    "    \n",
    "    # Temporal features\n",
    "    user_history['hour'] = user_history['datetime'].dt.hour\n",
    "    user_history['day_of_week'] = user_history['datetime'].dt.dayofweek\n",
    "    \n",
    "    # Most active hour\n",
    "    hour_counts = user_history['hour'].value_counts()\n",
    "    features['peak_hour'] = hour_counts.index[0] if len(hour_counts) > 0 else 0\n",
    "    features['hour_diversity'] = len(hour_counts) / 24\n",
    "    \n",
    "    # Weekend vs weekday ratio\n",
    "    weekend_plays = user_history[user_history['day_of_week'].isin([5, 6])].shape[0]\n",
    "    features['weekend_ratio'] = weekend_plays / len(user_history)\n",
    "    \n",
    "    # Artist concentration\n",
    "    if 'artist_name' in track_features.columns:\n",
    "        user_artists = user_plays.merge(track_features[['track_id', 'artist_name']], on='track_id')\n",
    "        artist_plays = user_artists.groupby('artist_name')['play_count'].sum()\n",
    "        features['unique_artists'] = artist_plays.shape[0]\n",
    "        features['artist_concentration'] = artist_plays.nlargest(5).sum() / artist_plays.sum()\n",
    "    \n",
    "    behavior_features.append(features)\n",
    "\n",
    "user_behavior = pd.DataFrame(behavior_features)\n",
    "print(f\"User behavior features shape: {user_behavior.shape}\")\n",
    "user_behavior.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Preferences (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract genre preferences if genre data is available\n",
    "if 'genre' in track_features.columns:\n",
    "    # Get user-genre play counts\n",
    "    user_genre_data = user_track_plays.merge(\n",
    "        track_features[['track_id', 'genre']], \n",
    "        on='track_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate genre distributions per user\n",
    "    user_genre_prefs = user_genre_data.groupby(['user_id', 'genre'])['play_count'].sum().unstack(fill_value=0)\n",
    "    \n",
    "    # Normalize to get genre preferences (percentages)\n",
    "    user_genre_prefs = user_genre_prefs.div(user_genre_prefs.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Keep top genres only to reduce dimensionality\n",
    "    top_genres = user_genre_prefs.sum().nlargest(20).index\n",
    "    user_genre_prefs = user_genre_prefs[top_genres]\n",
    "    \n",
    "    # Add prefix to column names\n",
    "    user_genre_prefs.columns = [f'genre_{col}' for col in user_genre_prefs.columns]\n",
    "    user_genre_prefs = user_genre_prefs.reset_index()\n",
    "    \n",
    "    print(f\"User genre preferences shape: {user_genre_prefs.shape}\")\n",
    "else:\n",
    "    print(\"Genre information not available\")\n",
    "    user_genre_prefs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all feature sets\n",
    "user_features = user_behavior.merge(user_audio_profiles, on='user_id', how='inner')\n",
    "\n",
    "if user_genre_prefs is not None:\n",
    "    user_features = user_features.merge(user_genre_prefs, on='user_id', how='left')\n",
    "    # Fill missing genre values with 0\n",
    "    genre_cols = [col for col in user_features.columns if col.startswith('genre_')]\n",
    "    user_features[genre_cols] = user_features[genre_cols].fillna(0)\n",
    "\n",
    "print(f\"Combined user features shape: {user_features.shape}\")\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"- Behavior features: {len([col for col in user_features.columns if col in user_behavior.columns])}\")\n",
    "print(f\"- Audio features: {len([col for col in user_features.columns if 'avg_' in col or 'std_' in col])}\")\n",
    "if user_genre_prefs is not None:\n",
    "    print(f\"- Genre features: {len([col for col in user_features.columns if col.startswith('genre_')])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate user_id from features\n",
    "feature_columns = [col for col in user_features.columns if col != 'user_id']\n",
    "X = user_features[feature_columns]\n",
    "\n",
    "# Check for highly skewed features\n",
    "skewness = X.apply(lambda x: stats.skew(x))\n",
    "highly_skewed = skewness[abs(skewness) > 1].index.tolist()\n",
    "\n",
    "print(f\"Highly skewed features ({len(highly_skewed)}):\")\n",
    "for feat in highly_skewed[:5]:\n",
    "    print(f\"  {feat}: skewness = {skewness[feat]:.2f}\")\n",
    "\n",
    "# Apply log transformation to highly skewed features\n",
    "X_transformed = X.copy()\n",
    "for feat in highly_skewed:\n",
    "    if X_transformed[feat].min() > 0:  # Only if all values are positive\n",
    "        X_transformed[feat] = np.log1p(X_transformed[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_transformed)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=feature_columns)\n",
    "\n",
    "# Visualize scaled feature distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "sample_features = ['total_plays', 'unique_tracks', 'avg_danceability', \n",
    "                   'avg_energy', 'track_diversity', 'artist_concentration']\n",
    "sample_features = [f for f in sample_features if f in X_scaled_df.columns][:6]\n",
    "\n",
    "for i, feat in enumerate(sample_features):\n",
    "    axes[i].hist(X_scaled_df[feat], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'{feat} (scaled)')\n",
    "    axes[i].set_xlabel('Scaled Value')\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to understand feature importance\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot explained variance\n",
    "cumsum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components_90 = np.argmax(cumsum_var >= 0.9) + 1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         pca.explained_variance_ratio_, 'bo-', label='Individual')\n",
    "plt.plot(range(1, len(cumsum_var) + 1), \n",
    "         cumsum_var, 'ro-', label='Cumulative')\n",
    "plt.axhline(y=0.9, color='g', linestyle='--', label='90% threshold')\n",
    "plt.axvline(x=n_components_90, color='g', linestyle='--')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Components needed for 90% variance: {n_components_90}\")\n",
    "print(f\"Original features: {X_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top features for first 3 principal components\n",
    "n_top_features = 10\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i in range(3):\n",
    "    # Get feature loadings for this component\n",
    "    loadings = pd.Series(pca.components_[i], index=feature_columns)\n",
    "    top_features = loadings.abs().nlargest(n_top_features)\n",
    "    \n",
    "    # Plot\n",
    "    loadings[top_features.index].plot(kind='barh', ax=axes[i])\n",
    "    axes[i].set_title(f'PC{i+1} Top Features (Var: {pca.explained_variance_ratio_[i]:.1%})')\n",
    "    axes[i].set_xlabel('Loading')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different feature sets for different purposes\n",
    "\n",
    "# 1. Full feature set (scaled)\n",
    "user_features_scaled = user_features.copy()\n",
    "user_features_scaled[feature_columns] = X_scaled\n",
    "\n",
    "# 2. PCA-reduced features\n",
    "pca_reducer = PCA(n_components=n_components_90)\n",
    "X_pca_reduced = pca_reducer.fit_transform(X_scaled)\n",
    "pca_columns = [f'PC{i+1}' for i in range(n_components_90)]\n",
    "user_features_pca = pd.DataFrame(X_pca_reduced, columns=pca_columns)\n",
    "user_features_pca['user_id'] = user_features['user_id'].values\n",
    "\n",
    "# 3. Selected important features only\n",
    "# Select based on PCA loadings and domain knowledge\n",
    "important_features = ['user_id', 'total_plays', 'unique_tracks', 'track_diversity',\n",
    "                     'avg_danceability', 'avg_energy', 'avg_valence', \n",
    "                     'std_danceability', 'std_energy', 'std_valence']\n",
    "\n",
    "# Add artist concentration if available\n",
    "if 'artist_concentration' in user_features.columns:\n",
    "    important_features.append('artist_concentration')\n",
    "\n",
    "# Add top genre features if available\n",
    "if user_genre_prefs is not None:\n",
    "    genre_cols = [col for col in user_features.columns if col.startswith('genre_')]\n",
    "    genre_importance = user_features[genre_cols].mean().nlargest(5)\n",
    "    important_features.extend(genre_importance.index.tolist())\n",
    "\n",
    "# Filter to available features\n",
    "important_features = [f for f in important_features if f in user_features.columns]\n",
    "user_features_selected = user_features[important_features].copy()\n",
    "\n",
    "# Scale selected features\n",
    "selected_feature_cols = [col for col in important_features if col != 'user_id']\n",
    "scaler_selected = StandardScaler()\n",
    "user_features_selected[selected_feature_cols] = scaler_selected.fit_transform(\n",
    "    user_features_selected[selected_feature_cols]\n",
    ")\n",
    "\n",
    "print(\"Feature sets created:\")\n",
    "print(f\"1. Full features (scaled): {user_features_scaled.shape}\")\n",
    "print(f\"2. PCA features: {user_features_pca.shape}\")\n",
    "print(f\"3. Selected features: {user_features_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations in selected features\n",
    "if len(selected_feature_cols) <= 15:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = user_features_selected[selected_feature_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "                fmt='.2f')\n",
    "    plt.title('Feature Correlations (Selected Features)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Too many features for correlation heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all feature sets\n",
    "user_features.to_csv('../data/processed/user_features_raw.csv', index=False)\n",
    "user_features_scaled.to_csv('../data/processed/user_features_scaled.csv', index=False)\n",
    "user_features_pca.to_csv('../data/processed/user_features_pca.csv', index=False)\n",
    "user_features_selected.to_csv('../data/processed/user_features_selected.csv', index=False)\n",
    "\n",
    "# Save scalers for later use\n",
    "import joblib\n",
    "joblib.dump(scaler, '../models/feature_scaler_full.pkl')\n",
    "joblib.dump(scaler_selected, '../models/feature_scaler_selected.pkl')\n",
    "joblib.dump(pca_reducer, '../models/pca_reducer.pkl')\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"- user_features_raw.csv: Original features\")\n",
    "print(\"- user_features_scaled.csv: All features, standardized\")\n",
    "print(\"- user_features_pca.csv: PCA-reduced features\")\n",
    "print(\"- user_features_selected.csv: Selected important features\")\n",
    "print(\"\\nSaved models:\")\n",
    "print(\"- feature_scaler_full.pkl\")\n",
    "print(\"- feature_scaler_selected.pkl\")\n",
    "print(\"- pca_reducer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature summary\n",
    "print(\"=== FEATURE ENGINEERING SUMMARY ===\")\n",
    "print(f\"\\nTotal users processed: {len(user_features):,}\")\n",
    "print(f\"Total features created: {len(feature_columns)}\")\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"- Listening behavior: {len([f for f in feature_columns if f in user_behavior.columns])}\")\n",
    "print(f\"- Audio preferences: {len([f for f in feature_columns if 'avg_' in f or 'std_' in f])}\")\n",
    "if user_genre_prefs is not None:\n",
    "    print(f\"- Genre preferences: {len([f for f in feature_columns if f.startswith('genre_')])}\")\n",
    "print(f\"\\nDimensionality reduction:\")\n",
    "print(f\"- Original dimensions: {len(feature_columns)}\")\n",
    "print(f\"- PCA components (90% var): {n_components_90}\")\n",
    "print(f\"- Selected features: {len(selected_feature_cols)}\")\n",
    "\n",
    "# Feature statistics\n",
    "print(\"\\n=== KEY FEATURE STATISTICS ===\")\n",
    "key_stats = user_features[['total_plays', 'unique_tracks', 'track_diversity']].describe()\n",
    "print(key_stats.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}